{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Anna Bialas<br>Individual Assignment #1<br>PPDS'17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to store the \\#1 trending topic along with its metadata (tweet volume, query, datetime as of which it was trending) for WOEID \\#2459115 (NYC). I store the topics every 20 mintues in a table called \"trends\" which has 5 columns:\n",
    "* <em>trend_id</em> - Made up of the query + timestamp (converted from datetime) of its collection. Attached to the trending topic at the time of its collection (if a topic is trending for a long time, it will be stored in the database multiple times, each time with a different trend_id);\n",
    "* <em>trend</em> - The name of the trend (oftentimes a hashtag);\n",
    "* <em>query</em> - Essentially the same as trend, except that its special characters are converted to '%' + corresponding ASCII hex code;\n",
    "* <em>tweet_volume</em> - How many tweets about the topic have been posted (I noticed sometimes the Twitter API outputs \"None\");\n",
    "* <em>date</em> - Date & time of when the API call was made to retrieve the trending topics list (stored in UTC &plusmn; 00).\n",
    "\n",
    "Potential use cases for this mini database: \n",
    "* Seeing how much time on average topics remain \\#1 trends;\n",
    "* Seeing if \"special\" dates result in \"special\" topics trending (e.g. Valentine's Day)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "*Identify a web API that returns data that change over time. You should pick a data source for which historic data are not readily and easily accessible. Some default options:  Twitter trending topics, NYTimes Top Stories together with Alchemy Entity extraction.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_oauthlib import OAuth1\n",
    "import json\n",
    "\n",
    "# Keys and Tokens for my app:\n",
    "consumer_key = 'MRm0XSAgnewHBJjho8E7jqp0K'\n",
    "consumer_secret = 'KAsY7286zChj1ZPrb708wfjxpBWw6zNAEYuq6Elh90OCBwUhXh'\n",
    "access_token = '796895774449733634-Xg0JkreBt7zZzjB75o8DSOPLYHDkveR'\n",
    "access_secret = 'sOB8ZodZ7P4A80Oo8eFbxbULIGDWQk2s8YzKQxEvK9SKz'\n",
    "\n",
    "# Authenticate:\n",
    "auth = OAuth1(consumer_key, consumer_secret, access_token, access_secret)\n",
    "print(auth)\n",
    "\n",
    "# Check if successful:\n",
    "url_oauth = 'https://api.twitter.com/1.1/account/verify_credentials.json'\n",
    "res = requests.get(url_oauth, auth=auth)\n",
    "\n",
    "print(\"My name is\", res.json()[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "*Create a database and the corresponding set of tables for storing the data, following the paradigm of the Citibike example. You should model the database properly to allow for storing of the data that are changing over time. Our approach with the Citibike database where we used two tables should provide guidance for that.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import MySQLdb as mdb\n",
    "import sys\n",
    "\n",
    "# Setup the database in which we will store the trends (meta)data:\n",
    "def connectDB():\n",
    "    con = mdb.connect(host = 'localhost', # My IP: 54.198.1.244\n",
    "                      user = 'root', \n",
    "                      passwd = 'dwdstudent2015', \n",
    "                      charset = 'utf8', use_unicode=True);\n",
    "    return con\n",
    "\n",
    "def createTwitterDB(con, db_name):\n",
    "    ''' \n",
    "    Connects to the database and creates (if it does not exist)\n",
    "    the database and the tables needed to store the data\n",
    "    '''\n",
    "    # Query to create the db:\n",
    "    create_db_query = \"CREATE DATABASE IF NOT EXISTS {0} DEFAULT CHARACTER SET 'utf8'\".format(db_name)\n",
    "\n",
    "    # Create the db:\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(create_db_query)\n",
    "    cursor.close()\n",
    "    pass\n",
    "\n",
    "def createTable(con, db_name, table_name):\n",
    "    cursor = con.cursor()\n",
    "    # Create a table to store trends:\n",
    "    create_table_query = '''CREATE TABLE IF NOT EXISTS {0}.{1} \n",
    "                                    (\n",
    "                                    trend_id varchar(250),\n",
    "                                    trend varchar(250),\n",
    "                                    query varchar(250),\n",
    "                                    tweet_volume int,\n",
    "                                    date datetime,\n",
    "                                    PRIMARY KEY(trend_id)\n",
    "                                    )'''.format(db_name, table_name)\n",
    "    cursor.execute(create_table_query)\n",
    "    cursor.close()\n",
    "\n",
    "con = connectDB()\n",
    "db_name = 'twitterv2'\n",
    "createTwitterDB(con, db_name)\n",
    "table_name = 'trends'\n",
    "createTable(con, db_name, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "*Write Python code that connects to the API, fetches the data, and stores the data in the database.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Fetch trending topics:\n",
    "url_trending = 'https://api.twitter.com/1.1/trends/place.json?id=2459115'\n",
    "res = requests.get(url_trending, auth=auth)\n",
    "\n",
    "# Check if successful:\n",
    "print(res, res.status_code, res.headers['content-type'])\n",
    "print(res.url)\n",
    "\n",
    "# Store first 50 \"trends\" in a variable:\n",
    "top50_trends = res.json()\n",
    "top50_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "def storeTrends(con, top50_trends):\n",
    "   \n",
    "    db_name = 'twitterv2'\n",
    "    table_name = 'trends'\n",
    "    \n",
    "    # Parse the datetime string and convert it to a timestamp:\n",
    "    date_str = top50_trends[0]['as_of']\n",
    "    date =  datetime.strptime(date_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    timestamp = calendar.timegm(date.utctimetuple())\n",
    "    \n",
    "    # Loop through each trend and assign its properties to specific fields in the table:\n",
    "    # (In this case, looping is not necessary since I am storing just one trend. However, I am leaving this code here \n",
    "    # so that any alterations to how many trending topics are being stored can be easily accomplished.)\n",
    "    for i, item in enumerate(top50_trends[0]['trends'][:1]):\n",
    "        trend_id = ''.join([item['query'], str(timestamp)])\n",
    "        trend = item['name']\n",
    "        query = item['query']\n",
    "        tweet_volume = item['tweet_volume']\n",
    "        date = date\n",
    "        # Insert the object into the db:\n",
    "        insertTrend(con, db_name, table_name, trend_id, trend, query, tweet_volume, date)\n",
    "    \n",
    "    # Writes the data in the db:\n",
    "    con.commit()\n",
    "    return\n",
    "# Function for inserting the trend: \n",
    "def insertTrend(con, db_name, table_name, trend_id, trend, query, tweet_volume, date):\n",
    "    query_template = '''INSERT IGNORE INTO {0}.{1}(trend_id, trend, query, tweet_volume, date) \n",
    "                VALUES (%s, %s, %s, %s, %s)'''.format(db_name, table_name)\n",
    "\n",
    "    cursor = con.cursor()\n",
    "    query_parameters = (trend_id, trend, query, tweet_volume, date)\n",
    "    cursor.execute(query_template, query_parameters)\n",
    "    cursor.close()\n",
    "\n",
    "\n",
    "storeTrends(con, top50_trends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "*Convert your code into a self-executable Python script and schedule it to run periodically using cron. You do not need to schedule the script to run too often. For example, for NY Times news stories and Twitter trending topics, fetching them every hour is more than sufficient.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Storage in crontab:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter task every 20 minutes:                                                                                                         \n",
    "0,20,40 * * * * /home/ubuntu/ipynb/Student_Notebooks/trends_store.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Access the db:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%sql mysql://root:dwdstudent2015@54.198.1.244:3306/twitterv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Show tables:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "show tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Look at some results:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT *\n",
    "FROM trends\n",
    "LIMIT 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
